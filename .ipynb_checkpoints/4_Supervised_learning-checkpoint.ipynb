{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Machine Learning For Chemists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this docuemnt you need to install tensorflow (Sorry!)\n",
    "\n",
    "Probably not needed on a newish install!\n",
    "\n",
    " `conda upgrade conda`\n",
    " \n",
    " `conda upgrade --all`\n",
    "\n",
    "create a new environment and install CPU version of tensorflow:\n",
    "\n",
    " `conda create -n tf tensorflow jupyter nb_conda`\n",
    "\n",
    "switch to it:\n",
    "\n",
    " `conda activate tf`\n",
    "\n",
    "add required moduiles:\n",
    "\n",
    " `pip install matplotlib pillow`\n",
    "\n",
    "start an environment:\n",
    "\n",
    " `jupyter notebook`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This checks that your install is working well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.tools'; 'tensorflow.python' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-07cd712cceb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TensorFlow version: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;31m# We still need all the names that are toplevel on tensorflow_core\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_core\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;31m# These should not be visible in the main tf module.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.tools'; 'tensorflow.python' is not a package"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version: \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important** Don't try to understand everything that this code does. This is bleeding edge whistle-stop tour designed to show you what is and isn't possible, not to teach you how to make a neural network! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some stuff. Keras is the nice front end for TensorFlow, TensorFlow is the library for neural networks, this is what google runs its machine learning systems on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import PIL\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gets the labels for photos. The NN just outputs a vector of numbers and we need these labels in order to understand the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "#imagenet_labels = np.array(open(labels_path).read().splitlines())\n",
    "imagenet_labels = np.array(open('NNdata/ImageNetLabels.txt').read().splitlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks can be used a **function approximators** or **pattern matchers**, but they have been very sucessful in **classification** problems. \n",
    "\n",
    "Regression models are supervised learning for **continuous** data, where we have data, we fit a **model** to it and we want to predict an output value. \n",
    "\n",
    "Neural networks can be used as supervised learning for **discrete** data, where we have a datapoint and we want to classify it, based on what we know about the data and the world in general.\n",
    "\n",
    "In this notebook you will do some classifications with neural networks. \n",
    "\n",
    "Like in multivariate regression, we learn from a dataset X. For image recognition, that dataset is called ImageNet and containes 1.3 million example photos from 1000 categories. This data is chopped up and manipulated (i.e. crops are taken and the images are flipped) and this makes many times more data. Each image is labelled with the object the image contains. The data are messy and badly labelled, but there is a lot of it (due to all those human volunteers putting their pictures on flickr!). **Deep-neural networks require vast amounts of labelled data: big data**\n",
    "\n",
    "In this section we are going to download the pre-trained models and test them out on some data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads a few pretrained NN models. Inception_v3 is the famous deep-NN from google you may have heard of. Vgg19 is a nice standard model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras\n",
    "#import numpy as np\n",
    "from tensorflow.keras.applications import vgg19, inception_v3, resnet50, mobilenet\n",
    "from tensorflow.keras.applications import vgg16\n",
    " \n",
    "#Load the VGG model\n",
    "vgg_model = vgg16.VGG16(weights='imagenet')\n",
    " \n",
    "#Load the Inception_V3 model\n",
    "inception_model = inception_v3.InceptionV3(weights='imagenet')\n",
    " \n",
    "#Load the ResNet50 model\n",
    "#resnet_model = resnet50.ResNet50(weights='imagenet')\n",
    " \n",
    "#Load the MobileNet model\n",
    "mobilenet_model = mobilenet.MobileNet(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we're going to do is load in some images and see how well the NNs do at classifying the images. (This code also reshapes the image so it will fit into the NN, don't worry about this). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This loads in an image from the folder NNdata -- make sure you have it!\n",
    "filename = 'NNdata/pure_images/ILSVRC2012_val_00001218.JPEG'\n",
    "# load an image in PIL format\n",
    "original = load_img(filename, target_size=(224, 224))\n",
    " \n",
    "# convert the PIL image to a numpy array\n",
    "# IN PIL - image is in (width, height, channel)\n",
    "# In Numpy - image is in (height, width, channel)\n",
    "numpy_image = img_to_array(original)\n",
    "print('numpy array size',numpy_image.shape)\n",
    " \n",
    "# Convert the image / images into batch format\n",
    "# expand_dims will add an extra dimension to the data at a particular axis\n",
    "# We want the input matrix to the network to be of the form (batchsize, height, width, channels)\n",
    "# Thus we add the extra dimension to the axis 0.\n",
    "image_batch = np.expand_dims(numpy_image, axis=0)\n",
    "print('image batch size', image_batch.shape)\n",
    "plt.imshow(np.uint8(image_batch[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chunk of code will pre-process the image, and then asks the `vgg_model` to predict the classes for the image. This is the same as we did for the multivariate regression, except now our data is columns of pixels. The output `predictions` is a 1000-unit long vector telling you that chance that each of the 1000 classes is present in the image. We then take the top-5 highest probabilities (which I've chosen to present as percentages) and see if we agree with the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare the image for the VGG model\n",
    "processed_image = vgg19.preprocess_input(image_batch.copy())\n",
    " \n",
    "# get the predicted probabilities for each class\n",
    "predictions = vgg_model.predict(processed_image)\n",
    "# print predictions\n",
    "\n",
    "#_ = plt.title(\"Prediction: \" + predicted_class_name.title())\n",
    "# convert the probabilities to class labels\n",
    "# We will get top 5 predictions which is the default\n",
    "predicted_top_5 = tf.keras.applications.vgg16.decode_predictions(predictions)[0]\n",
    "[(class_name, prob) for (number, class_name, prob) in predicted_top_5]\n",
    "\n",
    "print(\"Rank\\tprobability\\tname\")\n",
    "for i in range(5):\n",
    "    item = predicted_top_5[i]\n",
    "    print(\"{}.\\t {:.2f}%\\t\\t{}\".format(i+1, item[2]*100, item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll probably agree with the NN that there is both some sort of bird (that could be a kite) in the image and a pole. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change the file name in the above code and put in your own photos if you want to test out the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of files in the pure directory\n",
    "File_list_pure=[\"ILSVRC2012_val_00001079.JPEG\",\n",
    "\"ILSVRC2012_val_00001218.JPEG\",\n",
    "\"ILSVRC2012_val_00001671.JPEG\",\n",
    "\"ILSVRC2012_val_00003109.JPEG\",\n",
    "\"ILSVRC2012_val_00003594.JPEG\",\n",
    "\"ILSVRC2012_val_00003632.JPEG\",\n",
    "\"ILSVRC2012_val_00003866.JPEG\",\n",
    "\"ILSVRC2012_val_00004187.JPEG\",\n",
    "\"ILSVRC2012_val_00004255.JPEG\", \n",
    "\"ILSVRC2012_val_00004472.JPEG\",\n",
    "\"ILSVRC2012_val_00004613.JPEG\",\n",
    "\"ILSVRC2012_val_00004756.JPEG\",\n",
    "\"ILSVRC2012_val_00004920.JPEG\",\n",
    "\"ILSVRC2012_val_00005287.JPEG\",\n",
    "\"ILSVRC2012_val_00005747.JPEG\",\n",
    "\"ILSVRC2012_val_00005847.JPEG\", \n",
    "\"ILSVRC2012_val_00006432.JPEG\",\n",
    "\"ILSVRC2012_val_00006632.JPEG\", \n",
    "\"ILSVRC2012_val_00006722.JPEG\", \n",
    "\"ILSVRC2012_val_00007058.JPEG\",\n",
    "\"ILSVRC2012_val_00007307.JPEG\",\n",
    "\"ILSVRC2012_val_00009208.JPEG\",\n",
    "\"ILSVRC2012_val_00009396.JPEG\",\n",
    "\"ILSVRC2012_val_00009581.JPEG\",\n",
    "\"ILSVRC2012_val_00011045.JPEG\",\n",
    "\"ILSVRC2012_val_00012630.JPEG\",\n",
    "\"ILSVRC2012_val_00013772.JPEG\",\n",
    "\"ILSVRC2012_val_00014336.JPEG\"]\n",
    "print(\"The number of files is\", len(File_list_pure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Run the code below, and count how many of the images you think are correct, in that one of the top-5 labels in truely in the picture (do not score more than 1 item per image, so if there are two labels that match the image, that still counts as 1), then calculate the **top-5** accuracy on this test set.\n",
    "\n",
    "Then count the **top-1** accuracy, this time, give the NN a score of 1 if and only if the first class it suggests is in the picture. Record the top-1 accuracy below. \n",
    "\n",
    "This is how NNs are scored in competetions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "prob_pure=[]\n",
    "for this_file in File_list_pure:\n",
    "    c=c+1\n",
    "    # This loads in an image from the folder NNdata -- make sure you have it!\n",
    "    filename = 'NNdata/pure_images/' + this_file\n",
    "    # load an image in PIL format\n",
    "    original = load_img(filename, target_size=(224, 224))\n",
    "    numpy_image = img_to_array(original)\n",
    "    image_batch = np.expand_dims(numpy_image, axis=0)\n",
    "    print('Picture', c)\n",
    "    img = PIL.Image.fromarray(np.uint8(image_batch[0]))\n",
    "    display(img)\n",
    "    # prepare the image for the VGG model\n",
    "    processed_image = vgg19.preprocess_input(image_batch.copy())\n",
    "    # get the predicted probabilities for each class\n",
    "    predictions = vgg_model.predict(processed_image)\n",
    "    predicted_top_5 = tf.keras.applications.vgg19.decode_predictions(predictions)[0]\n",
    "    [(class_name, prob) for (number, class_name, prob) in predicted_top_5]\n",
    "    print(\"Rank\\tprobability\\tname - picture\",c)\n",
    "    for i in range(5):\n",
    "        item = predicted_top_5[i]\n",
    "        print(\"{}.\\t {:.2f}%\\t\\t{}\".format(i+1, item[2]*100, item[1]))\n",
    "        if i == 0:\n",
    "            prob_pure.append(item[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-5 Test Accuracy is :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-1 Test Accuracy is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you've calcualated the test accuracy, see how sure the neural network was it was correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Probability of correctness is {:.2f} plus or minus {:.2f}'.format(100*np.mean(prob_pure), 100*np.std(prob_pure)/np.sqrt(28)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem with neural networks is that we do not really know how they work, but we know that they do not work in the same way as humans beings. \n",
    "\n",
    "For example, look at this picture, can you identify it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads in an image from the folder NNdata -- make sure you have it!\n",
    "filename = 'NNdata/b.JPEG/b.JPEG'\n",
    "# load an image in PIL format\n",
    "original = load_img(filename, target_size=(224, 224))\n",
    "numpy_image = img_to_array(original)\n",
    "print('numpy array size',numpy_image.shape)\n",
    "image_batch = np.expand_dims(numpy_image, axis=0)\n",
    "print('image batch size', image_batch.shape)\n",
    "plt.imshow(np.uint8(image_batch[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code gets the NN to predict the class for this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the image for the VGG model\n",
    "processed_image = vgg19.preprocess_input(image_batch.copy())\n",
    "# get the predicted probabilities for each class\n",
    "predictions = vgg_model.predict(processed_image)\n",
    "# print predictions\n",
    "#_ = plt.title(\"Prediction: \" + predicted_class_name.title())\n",
    "# convert the probabilities to class labels\n",
    "# We will get top 5 predictions which is the default\n",
    "predicted_top_5 = tf.keras.applications.vgg16.decode_predictions(predictions)[0]\n",
    "[(class_name, prob) for (number, class_name, prob) in predicted_top_5]\n",
    "print(\"Rank\\tprobability\\tname\")\n",
    "for i in range(5):\n",
    "    item = predicted_top_5[i]\n",
    "    print(\"{}.\\t {:.2f}%\\t\\t{}\".format(i+1, item[2]*100, item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network cannot, even though it got it correct in when the colours were included. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proof that neural networks do not work like us is shown below with images designed to hack the neural networks.\n",
    "\n",
    "Reference for this bit: Nguyen A, Yosinski J, Clune J. \"Deep neural networks are easily fooled: High confidence predictions for unrecognizable images\". In *Proceedings of the IEEE conference on computer vision and pattern recognition 2015* (pp. 427-436)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2. \n",
    "As before, count up the top-5 and top1 accuracy and write them down. How do they compare to the previous set of images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "prob_fool=[]\n",
    "for this_file in range(16):\n",
    "    c=c+1\n",
    "    # This loads in an image from the folder NNdata -- make sure you have it!\n",
    "    filename = 'NNdata/fool_images/' + str(this_file + 1) + '.png'\n",
    "    # load an image in PIL format\n",
    "    original = load_img(filename, target_size=(224, 224))\n",
    "    numpy_image = img_to_array(original)\n",
    "    image_batch = np.expand_dims(numpy_image, axis=0)\n",
    "    print('Picture', c)\n",
    "    img = PIL.Image.fromarray(np.uint8(image_batch[0]))\n",
    "    display(img)\n",
    "    #f=plt.figure()\n",
    "    #plt.imshow(np.uint8(image_batch[0]))\n",
    "    #f.canvas.draw_idle()\n",
    "    # prepare the image for the VGG model\n",
    "    processed_image = mobilenet.preprocess_input(image_batch.copy())\n",
    "    # get the predicted probabilities for each class\n",
    "    predictions = mobilenet_model.predict(processed_image)\n",
    "    predicted_top_5 = tf.keras.applications.vgg19.decode_predictions(predictions)[0]\n",
    "    [(class_name, prob) for (number, class_name, prob) in predicted_top_5]\n",
    "    print(\"Rank\\tprobability\\tname - picture\",c)\n",
    "    for i in range(5):\n",
    "        item = predicted_top_5[i]\n",
    "        print(\"{}.\\t {:.2f}%\\t\\t{}\".format(i+1, item[2]*100, item[1]))\n",
    "        if i == 0:\n",
    "            prob_fool.append(item[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-5 Test Accuracy is :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-1 Test Accuracy is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you've calcualated the test accuracy, see how sure the neural network was it was correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Probability of correctness is {:.2f} plus or minus {:.2f}'.format(100*np.mean(prob_fool), 100*np.std(prob_fool)/np.sqrt(28)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "So, neural networks give a very high certainty to images which are not images of objects and are thus easy to fool. \n",
    "\n",
    "It sees they pay attention to small and local features, colour and texture, rather than the overall shape. \n",
    "\n",
    "The problem is, it is easy to see that the neural network answers are wrong in the visual realm, it would not be as easy to spot an error like this in a quantum chemistry approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a neural network: the effect of dataset size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will train a neural network on a set of data called MNIST, which is a database of 60,000 images of handwritten digits. (If you ever wondered how letters got to you, this is how automated postcode readers work). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch is a step, and we will train for 10 epochs.\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gets the mnist data and sets up the test and train datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000,28,28,1)\n",
    "x_test = x_test.reshape(10000,28,28,1)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code prints out the first 10 digits as an example of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    img = PIL.Image.fromarray(x_train[i].reshape((28,28)))\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll make a training set of only 1000 images, that should be more than enough, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_small=x_train[0:1000]\n",
    "y_train_small=y_train[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section sets up the neural network model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiates the model\n",
    "model = Sequential()\n",
    "# bottom layer takes in the pictures, and does a convolution on them to look for edges\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1)))\n",
    "# second layers takes in the output of the first and does a convolution on that data\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# max pooling, we take the largest number of the convolutions\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# dropout - some neurons are randomly removed during training as this reduces overtraining!\n",
    "model.add(Dropout(0.25))\n",
    "# changes the shape of the output - don't worry about this, it's just reshaping the data\n",
    "model.add(Flatten())\n",
    "# third layer, we add 128 feed-forward neurons\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# tehy're droped out randomly as well!\n",
    "model.add(Dropout(0.5))\n",
    "# we use the softmax activation on the output \n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the regularisation models, neural networks are a bit more complex. This sets up the **loss function** which tells the NN how bad the error is, choses the optimiser and tells the NN to measure accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the bit where it does the fit. Unlike the regression models we ran yesterday, fitting a deep NN takes a long time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits the NN to the input data (train and validation)\n",
    "model.fit(x_train_small, y_train_small,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "# This scores the model on the test set\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy: {:.2f}%'.format(score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watch the a loss improve with epoch (on the training set), and val_loss is the loss on the validation set, the val_acc is the accuracy on the validation set, the acc is the accracy on the trianing set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That;s OK, but not great, let's see what happens when we use all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try using ALL the data\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy: {:.2f}%'.format(score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Conclusion: \n",
    "\n",
    "You've just trained your first neural network. \n",
    "\n",
    "More data is better when less when training a neural network, but we really need to make sure that it is data of good quality. \n",
    "\n",
    "We can get away with less data if it is chosen in an intelligent way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
